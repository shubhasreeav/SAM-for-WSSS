{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "10UxLp5d0UDiX0zeDwcRHeip4SBlphkEa",
      "authorship_tag": "ABX9TyNTxvx7XFtbJy4SjL1SFXaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhasreeav/SAM-for-WSSS/blob/main/SAM_FLOODNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B4nZ-MKjc2Z",
        "outputId": "f33c1160-910f-4c51-ea04-14555a2f480a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  2 09:54:38 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2d3epK1IESs",
        "outputId": "9018d6e3-8f16-48c0-b549-9213a152bcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2PqafO3n4jc",
        "outputId": "a235c301-50ac-490b-b57e-69df5f11bab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtogQ9Tyn_CR",
        "outputId": "a8a91025-c946-4650-c7a6-d19d60ccf7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYREyYmMoFcb",
        "outputId": "924a7bbc-966f-4102-8de1-7977034682ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights"
      ],
      "metadata": {
        "id": "WeO1L14eoInk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Vg3RLUoJPc",
        "outputId": "f702cbc3-eebb-41c8-bac9-c4e65516d7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/sam_vit_h_4b8939.pth ; exist: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/data\n",
        "\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg -P {HOME}/data\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg -P {HOME}/data\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg -P {HOME}/data\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg -P {HOME}/data"
      ],
      "metadata": {
        "id": "4_PnveNKoMKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\""
      ],
      "metadata": {
        "id": "m8CbNzJDoO_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ],
      "metadata": {
        "id": "9HAFj5vioSA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "mask_predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "SIvK4EW_oU0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "nj0jHNnmoXrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building\n",
        "image_path='/content/drive/MyDrive/work3/y4_floodnet_test'\n",
        "label_path='/content/drive/MyDrive/work3/prediction'\n",
        "images=glob.glob(image_path+'/*.jpg')\n",
        "\n",
        "for img in images:\n",
        "\n",
        "  image_bgr = cv2.imread(img)\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "  height, width, _ = image_rgb.shape\n",
        "  mask_predictor.set_image(image_rgb)\n",
        "  basenamef=os.path.basename(img)\n",
        "  basename=basenamef.split('.')[0]\n",
        "  label=label_path+'/'+basename+'.txt'\n",
        "\n",
        "\n",
        "  lines=[]\n",
        "  masks_all=[]\n",
        "  scores_all=[]\n",
        "  logits_all=[]\n",
        "  with open(label) as f:\n",
        "      for line in f:\n",
        "        lines.append(line.strip())\n",
        "  for i in range(len(lines)):\n",
        "      elements = lines[i].split()  # Split by spaces or the appropriate delimiter\n",
        "      if len(elements) >= 5:\n",
        "\n",
        "        if int(elements[0])==1:\n",
        "          [ x1,y1,x2,y2] = np.array([int(float(elements[1])*width), int(float(elements[2])*height), int(float(elements[3])*width), int(float(elements[4])*height)])\n",
        "          box=np.array([int(elements[1]),int(elements[2]),int(elements[3]),int(elements[4])])\n",
        "          masks, scores, logits = mask_predictor.predict(\n",
        "        box=box,\n",
        "        multimask_output=True)\n",
        "\n",
        "          masks_all.append(masks)\n",
        "          scores_all.append(scores)\n",
        "          logits_all.append(logits)\n",
        "      else:\n",
        "          print(f\"Line {i} does not have enough elements.\")\n",
        "  if len(masks_all)>0:\n",
        "    combined_mask=np.zeros_like(masks_all[0])\n",
        "    for i in range(len(masks_all)):\n",
        "      combined_mask+=masks_all[i]\n",
        "    mask_int = np.where(combined_mask, 255, 0).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "    full_mask=np.zeros_like((1080,1920))\n",
        "    for channel in range(mask_int.shape[0]):\n",
        "      # Extract each channel as a 2D array\n",
        "      channel_data = mask_int[channel]\n",
        "\n",
        "      # Create an image from the channel data\n",
        "      channel_image = Image.fromarray(channel_data, mode='L')  # 'L' mode for grayscale\n",
        "\n",
        "      # Define the file path to save the channel image\n",
        "      file_path = f\"/content/drive/MyDrive/work3/FloodNet/masks_building/channel/{basename}_mask_{channel}.png\"  # Update the file path and format as needed\n",
        "\n",
        "      # Save the channel image\n",
        "      #channel_image.save(file_path)\n",
        "      if channel==0:\n",
        "        mask1=channel_data\n",
        "      if channel==1:\n",
        "        mask2=channel_data\n",
        "      if channel==2:\n",
        "        mask3=channel_data\n",
        "    full_mask=np.zeros_like(mask1)\n",
        "    combined_mask = np.logical_or(np.logical_or(mask1 == 255, mask2 == 255), mask3 == 255)\n",
        "\n",
        "  # Assign 255 where the combined condition is True in 'full_mask'\n",
        "    full_mask[combined_mask] = 255\n",
        "    file_path = f\"/content/drive/MyDrive/work3/building/{basename}.jpg\"\n",
        "    cv2.imwrite(file_path,full_mask)\n",
        "\n"
      ],
      "metadata": {
        "id": "fvydlETIoauy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vehicle\n",
        "image_path='/content/drive/MyDrive/work3/y4_floodnet_test'\n",
        "label_path='/content/drive/MyDrive/work3/prediction'\n",
        "images=glob.glob(image_path+'/*.jpg')\n",
        "\n",
        "for img in images:\n",
        "\n",
        "  image_bgr = cv2.imread(img)\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "  height, width, _ = image_rgb.shape\n",
        "  mask_predictor.set_image(image_rgb)\n",
        "  basenamef=os.path.basename(img)\n",
        "  basename=basenamef.split('.')[0]\n",
        "  label=label_path+'/'+basename+'.txt'\n",
        "\n",
        "\n",
        "  lines=[]\n",
        "  masks_all=[]\n",
        "  scores_all=[]\n",
        "  logits_all=[]\n",
        "  with open(label) as f:\n",
        "      for line in f:\n",
        "        lines.append(line.strip())\n",
        "  for i in range(len(lines)):\n",
        "      elements = lines[i].split()  # Split by spaces or the appropriate delimiter\n",
        "      if len(elements) >= 5:\n",
        "\n",
        "        if int(elements[0])==5:\n",
        "          [ xc,yc,w,h] = np.array([int(float(elements[1])*width), int(float(elements[2])*height), int(float(elements[3])*width), int(float(elements[4])*height)])\n",
        "          box=np.array([int(elements[1]),int(elements[2]),int(elements[3]),int(elements[4])])\n",
        "          masks, scores, logits = mask_predictor.predict(\n",
        "        box=box,\n",
        "        multimask_output=True)\n",
        "\n",
        "          masks_all.append(masks)\n",
        "          scores_all.append(scores)\n",
        "          logits_all.append(logits)\n",
        "      else:\n",
        "          print(f\"Line {i} does not have enough elements.\")\n",
        "  if len(masks_all)>0:\n",
        "    combined_mask=np.zeros_like(masks_all[0])\n",
        "    for i in range(len(masks_all)):\n",
        "      combined_mask+=masks_all[i]\n",
        "    mask_int = np.where(combined_mask, 255, 0).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "    full_mask=np.zeros_like((1080,1920))\n",
        "    for channel in range(mask_int.shape[0]):\n",
        "      # Extract each channel as a 2D array\n",
        "      channel_data = mask_int[channel]\n",
        "\n",
        "      # Create an image from the channel data\n",
        "      channel_image = Image.fromarray(channel_data, mode='L')  # 'L' mode for grayscale\n",
        "\n",
        "      # Define the file path to save the channel image\n",
        "      file_path = f\"/content/drive/MyDrive/work3/FloodNet/masks_vehicle/channel/{basename}_mask_{channel}.png\"  # Update the file path and format as needed\n",
        "\n",
        "      # Save the channel image\n",
        "      #channel_image.save(file_path)\n",
        "      if channel==0:\n",
        "        mask1=channel_data\n",
        "      if channel==1:\n",
        "        mask2=channel_data\n",
        "      if channel==2:\n",
        "        mask3=channel_data\n",
        "    full_mask=np.zeros_like(mask1)\n",
        "    combined_mask = np.logical_or(np.logical_or(mask1 == 255, mask2 == 255), mask3 == 255)\n",
        "\n",
        "  # Assign 255 where the combined condition is True in 'full_mask'\n",
        "    full_mask[combined_mask] = 255\n",
        "    file_path = f\"/content/drive/MyDrive/work3/vehicle/{basename}.jpg\"\n",
        "    cv2.imwrite(file_path,full_mask)"
      ],
      "metadata": {
        "id": "DnXUZAE4vf9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tree\n",
        "image_path='/content/drive/MyDrive/work3/y4_floodnet_test'\n",
        "label_path='/content/drive/MyDrive/work3/prediction'\n",
        "images=glob.glob(image_path+'/*.jpg')\n",
        "\n",
        "for img in images:\n",
        "\n",
        "  image_bgr = cv2.imread(img)\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "  height, width, _ = image_rgb.shape\n",
        "  mask_predictor.set_image(image_rgb)\n",
        "  basenamef=os.path.basename(img)\n",
        "  basename=basenamef.split('.')[0]\n",
        "  label=label_path+'/'+basename+'.txt'\n",
        "\n",
        "\n",
        "  lines=[]\n",
        "  masks_all=[]\n",
        "  scores_all=[]\n",
        "  logits_all=[]\n",
        "  with open(label) as f:\n",
        "      for line in f:\n",
        "        lines.append(line.strip())\n",
        "  for i in range(len(lines)):\n",
        "      elements = lines[i].split()  # Split by spaces or the appropriate delimiter\n",
        "      if len(elements) >= 5:\n",
        "\n",
        "        if int(elements[0])==2:\n",
        "          [ xc,yc,w,h] = np.array([int(float(elements[1])*width), int(float(elements[2])*height), int(float(elements[3])*width), int(float(elements[4])*height)])\n",
        "          box=np.array([int(elements[1]),int(elements[2]),int(elements[3]),int(elements[4])])\n",
        "          masks, scores, logits = mask_predictor.predict(\n",
        "        box=box,\n",
        "        multimask_output=True)\n",
        "\n",
        "          masks_all.append(masks)\n",
        "          scores_all.append(scores)\n",
        "          logits_all.append(logits)\n",
        "      else:\n",
        "          print(f\"Line {i} does not have enough elements.\")\n",
        "  if len(masks_all)>0:\n",
        "    combined_mask=np.zeros_like(masks_all[0])\n",
        "    for i in range(len(masks_all)):\n",
        "      combined_mask+=masks_all[i]\n",
        "    mask_int = np.where(combined_mask, 255, 0).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "    full_mask=np.zeros_like((1080,1920))\n",
        "    for channel in range(mask_int.shape[0]):\n",
        "      # Extract each channel as a 2D array\n",
        "      channel_data = mask_int[channel]\n",
        "\n",
        "      # Create an image from the channel data\n",
        "      channel_image = Image.fromarray(channel_data, mode='L')  # 'L' mode for grayscale\n",
        "\n",
        "      # Define the file path to save the channel image\n",
        "      file_path = f\"/content/drive/MyDrive/work3/FloodNet/masks_tree/channel/{basename}_mask_{channel}.png\"  # Update the file path and format as needed\n",
        "\n",
        "      # Save the channel image\n",
        "      #channel_image.save(file_path)\n",
        "      if channel==0:\n",
        "        mask1=channel_data\n",
        "      if channel==1:\n",
        "        mask2=channel_data\n",
        "      if channel==2:\n",
        "        mask3=channel_data\n",
        "    full_mask=np.zeros_like(mask1)\n",
        "    combined_mask = np.logical_or(np.logical_or(mask1 == 255, mask2 == 255), mask3 == 255)\n",
        "\n",
        "  # Assign 255 where the combined condition is True in 'full_mask'\n",
        "    full_mask[combined_mask] = 255\n",
        "    file_path = f\"/content/drive/MyDrive/work3/tree/{basename}.jpg\"\n",
        "    cv2.imwrite(file_path,full_mask)"
      ],
      "metadata": {
        "id": "0NBaHSTAoeHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}